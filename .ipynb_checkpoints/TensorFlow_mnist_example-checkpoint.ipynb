{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers, models\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get MNIST Data. \n",
    "### MNIST data loacted in tensorflow > keras > datasets > mnist \n",
    "### Split data to (train images, train labels) and (test images, test labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are Total 60000 Train images and Train labels. (6000 images for single class)\n",
    "### Shape of single image is 28 x 28 (pixel)\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train images : (60000, 28, 28)\n",
      "Shape of Train labels :  (60000,)\n",
      "\n",
      "Shape of Test images :  (10000, 28, 28)\n",
      "Shape of Test labels :  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Train images :',train_images.shape)\n",
    "print('Shape of Train labels : ', train_labels.shape)\n",
    "print('\\nShape of Test images : ', test_images.shape)\n",
    "print(\"Shape of Test labels : \",test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels :  [5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print('Train labels : ',train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot first train image. \n",
    "### when value is close to 0 : dark \n",
    "### when value is close to 255 : white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
      "  159  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
      "  252 237   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
      "  233 252  57   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
      "   84 252 253 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
      "   96 189 253 167   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "   47  79 255 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
      "    0   0 253 243  50   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
      "    0   0 253 252 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
      "    0   0 255 253 196   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
      "    0   0 253 252 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
      "    7 135 253 186  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
      "  131 252 225  71   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      "  252 173   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
      "   56   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot First 10 Train images and Corresponding labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Train images in MNIST dataset\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAAuCAYAAAAWRMPkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAb4UlEQVR4nO2deXRV5b33P3s4Q05ycjKdjCfzREKQGQJCAVFQQdQqKlbFsUprS9t7tXfV9n2vvX3ftk6t9fY6VFAqIA6AqAxOzDKPQkhC5oTMZJ7OtPe+fwRBK7QQzk5c7f6sxVrhHE5+X85+9vcZfr/n2YKmaRgYGBgYDD7iUAswMDAw+FfFMGADAwODIcIwYAMDA4MhwjBgAwMDgyHCMGADAwODIcIwYAMDA4MhQr6Uf2wWLJqVYL20fAM3PXg1j2DoMHQYOgwd/2w64BIN2EowE4WZgVF1EezVPjN0GDoMHYaOf0odYCxBGBgYGAwZ/3IGLCe6aF40CWlLPHML2ih7Jh9h9PChlmVgQMtDk0jZF8Q9xTWUPzUJOTZmqCUZXAJyogs+c9H6YdbFf0ZHPSAISHY7BFkB6BuVRO10Ez6HgtQnkvKBl5af9vLiiBUUeBJ4duV3SfyvXbrJkZMTKX7UxdJbXiTX1INVkLj61kIeHXUH8tW6hb1opPBwGucPY/h9BZx+MA6loHhQ44t5wyj6aQjLZ7zCp1157PhJPtKWQ4OqYagRLBbEMAe+rAQaxwdh6tZwLjuE5vHoGldOiKd9Rh9PxH5ClGjmuZwWlMRoaGjUNe43dKQkoYTb6cy2476zjf/JW4nC15cvizzx/GbLPLIXH0HzefUTI0qIeZmU3RmO5bRA/DP6ecPlIrsSOPHrGN5Ne5H52x8h4mI/F1ARiS60kCA68iJoHiPij/MyM6eIWyK3AWAX+4gQ3XRpJt7vGMPW4Zl8kPtXulSRz1pziChUAinna0gZqRT9MIY/37CUiRYfvapAjV8F4NrYAj6ZNAXxQOFlNSj/zLH0RZlwfHgMtafnkj8vOOx0ZGkUtsQSJQ/u5ETKzqD4gTDWXvU8OWaRBv8ptplEpEFVMXRIMdE0zU2ne3Y3N2Ye47rQTwkT+9jck8OSyGtx/Vbfm19t70CqSGbPuARuDm7FLCuossh5Mzc6IGVnUHNDNNHXnmKK8wjDg04x1VpLlBQEfP28mNHmahJmLePR395H1m8KUdo79NEUGkLhD0J57ZqXuX/TQ0jh4ShtbbrEuhzk1GRO/Ec062a8QLMSTNgey8V/NlAixJE59Dzdx92JO0gwteGUurCLPpyiQIj4VUEW/tiWxZrVU5F7Yfa2x7E1agTX+7HvPIEaKEFnECwWhOxUih528Nys5XzH2oWIRI0i8m9l8ymtjGH/rOfpfsnKulenEfPCwG+0uisteDLchG8LGZABazYrclIPyY5WeoToAesYCEq4DWtSF1mmwbrlQcpKp35WDF2Te5mZUczokGpW1kyga10cgqrRFy2QvKET7cBx3TTIyYnUzkskfF4t/ydlGcPNTSgIFHmdeDWJ20K/YPPsbNTV6Sgny3TTofb2EtQgUOqOheBW3eJciNL7nPzohvXcbC8gWBCxCDImIahf29/clZIgMMXaweNz3ueddbMRdxzWR5QgItl9XGn1YYnuhcgw+BYasBIWwqzRx3GKfh4ru47YVUVc7FAycAbc0kmE1csNIWWEi1ZAOvMHdnskNnVcQbq1iRtDythQn0fqX8rQlDMX1uNB83pR3e5AyTlL4wNjSb69jJWJK8gz+zAJJgCSZY0cRwNVzS6Wdw7nNscB/po3mctZdRt/3XGON8eBcOkmJlgsdA0L56nRb/CzfbeTeXLwlh/kRBfls0N4ZuRSTqtefnFqLlXPZGM/WnHRDelSUaeOpvT78Itxa5gcVE65P4Kjvcn8IGUr1p/6AGjyh/J0yI2kHQh8fNFup2HhCBzz6viP5DeZHFRDjGSh3Cdy2+EHCX0zlMbxAgV3/olpUSf5OOY7iCcDr+OsHpuNvliNDGuDfkH+DrY6AZPgxylZqPN7+FXtLPbXJAGgaRDp6OHBlM+5K7QGAJMgkW5uRLGIuieSTIKELCsgDc18TMrJpOpmJ7YGjai3vvja4EqOjaFqtoOfRBzilbYJ9LyYQHDb3ov+3QEzYKWhkfJ3JnDNzAfp6bXw+OiPuS+0hoMeWLjp+6S/42dnqMzvJkkgQlrD7kCFviBSZhremR08m7KaJDmI7e5gnqq8jkhrD39K+pDy7iiiDms8HzqLG+YcR7Bent0MD6mnsCV2QJ8VctJx399GgtyOWGVF7e29LC0Xi+xKoOp7Sdw//yOmWNtY153C0TW5uDYcQtFj3VOUkHIyKFuk8Vr+67QqIdy872FCPgohtMpLQ76FH9+5jgcc1Wzp82Dq1GdE3jd1GKm3lfDHlLVEiWYkwUK5z8fN+x4m8QUZc0kFnSnpANhEL5qs78xAsNnwRvvJMjUBMqmhrZRlRBNZ6kRpbtY1NkDCuhqW183lVYeI5AV7jYf0pu6z76u2IJ699rvkP/gsGSaZRsXDE8ULiDx+Cr/u6kAUNDSTvimrC1Ex38nDt2/g+d1X49wRAyXlZ9/zpccx/ZaDmAQ/766YTuLHxy9p0BKw/5Hm95PwbjneI3FIvV5+d+8NJFy3jBeqZ5L4EUhbD2OTTWQdjUWzWXUbWX2JlJFK4c8jeHHkG8RJZt7vCeexTQuI2SNQmSMwwZFF4scaYXvLELR0ouZJzMv7gpPDsweU/JJysxgZtI7VwqgB6fU7LMxNPEKDEkr0wUAvxFyYnhHxRF1Vx/fDjlPn13i6cBZJb1Xj12E2AuC7ahSnFrlZNnopNb5IfvnB7aS/3YNUVACxTrzXOZlqK6Vb1Xiv7UqSPupCjxOr66bK/Czuc2IkC6U+P+s6R/GXXdNIX+VH2lcAsdG4IwbvrGy1vQN7oYmP8vMYHlHE4/GbWHhLLH3NKZg36W/A/qoa7I3N2CUJNA3N60Xxn7NWOTkRxWrHJiiATKtioqkiEkejfssyX6JoKolh7fS4XJj1W426IN4Ilcm2El52TEULtp59XQoNpSk3iEXOrdT4w7DVayidnZf0uwPapfjrG5CaT6MpCvbvTKLYHc8wRyO7wpII0jQ0nxd/ZXUgQ54X2ZVA1S1x/GzSenLNLezzhPLkiTkkfaRi21NG+JEoUFTU8moUnxfr6SRsgpk7I3Zz9x3jSfnVpcesmxlFrrkFUbj0m1YwmemLMjMxuIwWJQR7cUfA18LPh2i10jzaxJKM1aiaxuttk7F+4MBfc0KXeF235yPe18Tbw1bwdsc43lr3HTLfbkM9UYKiKnRfm8vNM/aSYZJZ1xPFtjVjSPzioC5a4nf6WRxzJ/gEgstNhFaqDCtoRyupQPN40EJs+CMGY2zXj+bz4nq/njemTOBnE4vIMYvkx1dyzDES8yBpuNASoJySRO0NLjKnVOCU+i2jyBtL6mp///qEXigKilekT/OSYW9mV2zKoH0XX+K5fjwZI07Rq1rw1AUjnq7pvzdFCf/wVLqv6cYmKCxtmELkvuZLHlgGfEyvnek143Z28dLEKfx2zHusmzgG5/Zk/BVVgQ73DQRZpvrOZL5z6yGuCi7ituP30rkrmvBiheATDfhbWqHl/EmOeMlDyKiWAcXtyPNhF0SamhxE+C8tKyxmpVJ7vUKuuYWnGkchtrTrbsBSmIOWebmMmFPEWAus7Ylj9eZ8sj+q0mVK2XPLRCIWVfFc6rvs6kvlnXenkbaqAaWsv03Iqck0jRV4JHIHu92h/HzrbeSuqsWvU/lX0JYCshtSEft80HgataMT9SsjPl+EjRjX4CZ8lNIKetrG0V/7ICINoDMPJFJWOvVXx9A9pZebhu3mjvC9mASJDtXL+6dHYd5/Utd2qvb2Yq41s8ttJ0TyoFx8cUFAkMLDqZor8HLyR/xXxVxcW1SUxv7ZiJiXSfFdVp4bvYIlbZOofzYD28l9lxxDv0WVw4XEvD2WN+ImcWv+ftb8aCKRR+OJKOjSNastpqeQPqeMX8V8yvwT9yAvjSR1Zxlabx+q9++XmJkFgbCggU29TaFeREHAVmSBizANQZaRXPF0jI2jbgb8fuoq6vxBbNo6hsw2nbLKX0HNTKL12j5Wut7npE/i18fnkra6D39tXcBjiTYbrQt6WHrGfH/39i2kvdWIUlqB5AilY1YOdbP93DNuOy2qhR8fu52MN/y6dthqby8cLDg7YhGvGEZPhgP1TJ6nLVvipriDNCse1jeOwFJxelDWOr+Kog1iRUpkBH3j0mjNNeM7c0yCO8PDwtFbuStsH3GSGRWVT/vC+OmB2wjeHkJM36UbzqWg+f2YOwRqfJG6xjkfckI8lfek8NCUzzjqTqJ5owvXjiIUnxc5LYXS+eH8/6tXYRf7WPXplaSv3TOwOAHWfRbN78f+aSHlKXm4FrTz/+a8xc6pWaw/dAUZ1lHIR8tQu7oCHrfytmhecK3lhM9B35oYYj4uwH8R6zJfVlwOZAnhq5i6QFPOTUTkuFiwWvC6IuiLMeO3CPTEifTFqSgOPxExbcyNq+CqoDre7coi6ROfLtUgX0VOS6F0Xgg/HrkBrybyw5MLcKyyIx48rMt6q2APYWH2XlySiSe33kT22k78USG0TsunIwOG55fzavJa0kwmnm4ZgbwpDGnPQV20fE2XLCPFRNORn0jtdQqjs8qxSv02O8XWxhzHEVZ0jKZ+dQrRVfonjQHQQEX7RumXnshxsVQtTMMxvYH7Eg+RaOqfIeaaG8gwWVDpH3pW+VT+s2geKc8LyIUFX1sj1hu75EYxD0KHJAgIY4dTvCCExdeu567QQp4+nd/fKcU6EfvctI2PZeLVBeRa6rn3i4VkvNUz4Laqa1pR6ewk8b06toljOXVDGL9K+oB5Mw+xKPgu4lfnEvLpiYCasJSTycQ5xxhp7mTByTuIPN57SYviXk2jts1BIjWXHFtRRFRNw391O6dsI5HODIK70lTUYIWw6C4Sw+rx+GXiTR5kUeVEUyztJRF80OBg8awt1PvCCDqmb1ZZtNupui2ehTd+xj2OItZ1J9G4K56U9UdRdZruC18py7M5eyi5205QShfz07cxJaSYWKkbp6Th1vxsrMsldkszip47rAQBOT6OxuuTaR2hkjeyil8mbMEk+DEJCuPMXkyCRJvq5uXuOBzlPhBE0PROHQ8NakwErllVvJrxFjFS0NnXRaxnfwIwCyqqBnJzp26bLy7EOFs5S+L1X5IRRuVSvMjK8hn/Q74FahWVmaEFeG6UWRM/DltVJNrYTu6P3slLzdMJfj0Mbf/Fl539LbrXdfjLK0l8rZPmqkzmz32EH4/bzNtXvsxDoXfjtw4n9M2BDd3PR/sVkTwQ8RE+TaN6j4uM2n9sZpLTScMIC92ahzc7RxL0sX1AsR07rTyeeQ0PZO2i1BWDT+tvtBPsFRT1xXGsPZ7ihmh8jUHY6iTsVSqu0h7Etkaqb4mDWVDW48Rfr28dqGdiFsPmnOSxyBOAmU0tI4g8rgxo48jFonZ189LnMxh3TTmH8l+ncbyHzb1pvNc4mpVF40h1tvCLlPWomkhDYTQhxYFrE99AlJDSk6m4I5Y7528mXO5hY1Mej+5bgHAqiKCsdt4ctZQMk4BFELkx8gj/fmsWOVUZKIWloOpvwl+uAcdaOjkQJjCwFnkJ8dq6KNmTxE9MN+FVZVr6bCiqiHBmNpgQ0sE9sbu4zga3pRxmY/Z0LKUVOqvqx9yhUeFx8t2QcnyxOnbK9A/gCh8OZvmMl8g09bG47iq2VGcwM/kki51bWHjtLpqVYLJNHQQLIm9qAopZQApzDLhDGpTCOqWlFft7h3EcT+aFh65l0e0lrB65hDtNC5G3xgbMdFQTBIseqvxBOA+pKHV/fx+9FBNN85x0Rtx+gr3uUF769Bqylh8d0OTP+dJujnfmszNrJKp0rqfeyigcpRBW2kd6cQ3K6XNJPg3wTxqJNKkNryaytzKFNI4MIPrFIYWHUz7LzCMx+/FpCqV+lT1Hshi2rVzXskC1p4ec59t4yPMQwUmd9HRZsRZbidvtIa2ph5P3JyKlqHzWPZywQh2nmYKANjGPkptsPPvd14mVO7hj/aMkrVfJPl6PLymK0odsuDWJQq/K531ZjLJWsWz6q9zb8zCuz8ZiP1wPHi+apqE0Numg8dyPs+zHeOOKKcSEhl5yedOl4K+qIeMPbpr2pWFu9+No7ALl3F3QkpbKz+5xMXvaX1C0wd0ib6/xs78lGTFqH6JJRbTZdKuRr7zVyTNXLWdj50geLr8C+7t2kgo62DpzPO3zg/hNwgZyTF4gCBWVH0dvZv6t6YRvC4JvswGLVitifCy+iGBEf38Li5AkxjurORmfBQEe9e3ozSKoyXvBcx0EiwUx2UXDVdHE31HJlLASHt5yL5lv913WxQ1duYfQv/P++UzOG2EmP/4k+91JhHxuG3Dsi6H1+mzGXllMvrWWRgUeK7uDuK0MSqG/UlhC5uKSb74xKpeglC7yLfCH2jgclT7dNAhjh1P2qMjKyX/ihCeBfz8wn9Q1fixfVOIdnkTZ/QJ/mfI6lb4onjhyI6YDdrqHefnemL38bvYqNo6/gs+35iH3CMg9EPdc4A1YapMp8nnIMMmMs8Dk0cXUj8tE3qxPOd6XKM3NBL3X3w7+tp0GtbZjmpgN03SVcF5MXT7a3EGYkAiyeREjI3QzYHemm1+fmIO0KYyktWUojQWogMudwY6sYVTGbKfcJ7KmbSyt3mCKW6OxbA7FXz/wogJdDViwWJDiY+kcFUvDJJGkMbX8yrULEZFGRWVzdRYJhwJfc7rtdBZSn++8C+NSeDh9E9Kpni1z07S9hMgeXnjjRrJ0PmzlH1HmicF5RN/db8Jdzfx30gfYBDNPt4yi+d1Eot/TP9n1dzV5fHi9QahoFDXHkHRQn9G4lJFK8WITa698kc09w3j5netJ/rQXqc/N6TlZeG5u54nsLaxrG8PGz8aRuawF9WQhUlwsW/Ins2LGJB6Ysp1Hb3+eHs3M40W3wnOB1xlxTODFadN5Nn4nAFPCSvjzuFziNwc+FoKAFO1Ebe+44GlvUpiDrqkZ2Cfo30mfD7ndTVtHMN2aD6e9G58rEqHmlC6xoj8yE3G4G7Xk4LkchCjhcTlISDlNitzN3EMP4fyTDUtDF9FuL2rDkctKl+piwIIsI0VF0jsykeprZW6dvocfRu4kTgrCo/n4wiuyrGU6vhOhAS3k1gQBEZUnk9fxg9zFRFY50Xp6ECwWiApHDQumfryd6FuqWZ22mg1dV7Bi1UzdT7q6GEyCgmKRdOsR5dRk0h0tOEQrKiorTownbV+nvscJXgRadR2+Vv3PYy59MJYPpz6LXVR5fscs4opUmsbaUKZ18GTeClJMp7nv6EJC3wglc9vJs0tF/ppThNScIucTB+tunsGSqVPAK5LzXIsuHYWj0s3uhmTccVuxCWaccheecA3BYgnokZhSmAM11UXN1Q4S159GPVl+toYf6F8rDw2h8+ph8GAzG4a/AZjxaRKDWKCBerwI65HJ7BgXx5iIGnZkxxOuU0GKY8Web1xTOdlFxUwzi5P280F3DuwIR968K2DXPrD3uyghBllRh6dRMdvOxDnHWBq3EZcchEeTKfT5WNsxhtd3TyF9lZ+UrYH9JgVNQ0Uk26QS90A5ZbGZhJUodCdI9E7t5sHhn3NN8Ana1SB+XTOXE1sySV3fNpjt6YJEyV30xJtw6PC7RauVwp/G8nrsOgDq/B6osCFWFuu+JfwfoVyRQbhL/4z6A3M+JVEWcWsaT05fgzRDY5i5HoX+OtMFex7CtUTG9Nk+lPMMCpT2DiJe203Ea2f+rpNOcdth+qZM5nBuMFdafdwU3M7aaYW0JsajBDDx1TIvF+f9lWxMe5l5XY8R6/MjuM91xmpkKE3jHNjmN/Bu7nJMgshxr8b25gzM7YPbaYecUnmneRz7ylLIWjF4MzZBlqm9IYF7537GCGsND65aRMbSwoBe+8AYsCAgx8bgT3TSkhtC1MIq1qe9eNZ4S30eVneOYemOaaSv8pK1c78uWxglL7QrNkS6eCvjQ0p/4KfE5yTX3IhLMtGhevlrx2heOTIF5yYLySt2fSvMF/pHwH6LPgkobUQmE8aWkGvqoUOFBQX3Er/Tj9qhX2LnYvGFmgi36b/jbHX1KEYGVZMotzPKeoo6v4PHy26l5kAC8dv9ZOyvRDl9Wt+ttReJrUHj4848JlkPAiJ+HRJf2YsKeM61EbtoIXL+KU5OjUJVzrW/vOQ6nk9czjiLQocKb3Zm8Pvtc0hZqyLv1uF4uotAlDQEkzx4s7aR2ZhmnWa2/RiLTnyPhO3+gJ9HfFkGLJjMiA47WryTsl+a+FHeVubbi84cRxlEm+rmlbaxvP7xdNJW95F14LCuX17Y3lp+fWwOsaNXMs7SS5bJTJapgzYVtrvt/KZ0DsqyaDICWPoWKFLMzXRkgR57fnx2M3n2Ohyild0eCf9aJ5YNu4d07fdLbMVNFNZFQQ79ZU+iPkcORi1o5P/eeD+tI0ByQ/KGHswFFaR214CmDflM4Ks4D7TzVsFYfuHch0XQp+qgvtdBoyJiEzQ+HLYGhp17T9E0fCh4NJXdbjt/PDWXytXpZL98UPcng5wPVRaItnSR56qjKz9H94Tkl5T8xMz7ea/y+/rZmF+LwLxp4PW+F+KyDNgzcyTdj3bwWNZGrrc1IiLSq0Gb6qbGb+LBLx4g9C+hZHxyuP+Ak0CpvgD+qhpSFyv86HuPcNfdn3Cd/RgAi4ruxr8yhqiPy/E3fMvMVwWvKiPp+O0IqoZbNZ3ZXfXtesaFv7KaoCIXn19pIja0CyU9DnQYiSqdnYS9sZuwr7z2bZn9/C1CbRPWgmyWjclkqq2E5r4QrEpg1YpPhDN34WJenbWEiZYeTIKEW/PTqyps7ktmf3cq205loG6OwPVBHTHlu4asw+7IgIWRn3PfqYUkVrYM2pbw8K1W/jxsBjuODmNYkT4HZF2WAZ+6SmbV8OXESF7aVXi3K48/HbwKocVMyoc+YnYeHxTj/Sr+2jrin6pj81PBbCYfgBDKgfJB38t/MdiqO9l6JIfZM44j6iTQUlzHyqPjmXLlSXpUC8K3abgHxO/oY/GE2/l93hoWPXAPw7qzUY8XDbWsIUM53YLrt7t4/7eRvE8kMtWBb7t7viD7sIXHF36fqxft5t7wXTxZO5eDO7JJ+sSLZX8J0Z3912Co75uQKnii4ma6T4WCZ/B24EUu2U3ZEshin26d9WUZcNrju/nF4xO+9lom5x7i+G2Y4n7bUQqKyXoEXiOZFPRJ7/rrG8hc2MAfyAEgQqc4A0XeX4j48RgOpaXwzLS3+Hn798j8z2Bdd+cZgObxEPXKbo68Aj9hMtBK2pm28W3qoyOX7EZbApnUDnlnEGj+5R5Lb/DtQ3W7iV16iA1PTmdZ/WTGTS5GSE4YalkGBrozNM/4MDD4G1S3m+DVe/Gshv40z+A/mNLAYLARtEtIdgiC0Azof6r6OZI1TXMaOgwdhg5Dxz+bDrhEAzYwMDAwCBzGGrCBgYHBEGEYsIGBgcEQYRiwgYGBwRBhGLCBgYHBEGEYsIGBgcEQYRiwgYGBwRBhGLCBgYHBEGEYsIGBgcEQYRiwgYGBwRDxvzs+SjjAUdmtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train labels match with Train label sequentialy\n",
      " [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "print('First 10 Train images in MNIST dataset\\n')\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(train_images[i])\n",
    "plt.show()\n",
    "print('\\nTrain labels match with Train label sequentialy\\n',train_labels[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important\n",
    "### Change data shape (60000 x 28 x 28) to (60000 x 28 x 28 x 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = tf.reshape(train_images, [-1, 28, 28, 1])\n",
    "test_images = tf.reshape(test_images, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select one convolution model below \n",
    "## There are 3 example models. \n",
    "## 3, 5, 7 layer each \n",
    "## MODEL 1 : 3 Layers with 1 Convolution layer  \n",
    "## MODEL 2 : 5 Layers with 2 Convolution layer \n",
    "## MODEL 3 : 7 Layers with 4 Convolution layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(model_number):\n",
    "    if model_number == 1:\n",
    "        model = keras.models.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28,1)),  # layer 1 \n",
    "                    keras.layers.MaxPool2D((2,2)),                                                  # layer 2 \n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(10, activation = 'softmax')])                                # layer 3\n",
    "\n",
    "    if model_number == 2:\n",
    "        model = keras.models.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(28,28,1)),     # layer 1 \n",
    "                    keras.layers.MaxPool2D((2,2)),                                                  # layer 2\n",
    "                    keras.layers.Conv2D(64, (3,3), activation = 'relu'),                            # layer 3 \n",
    "                    keras.layers.MaxPool2D((2,2)),                                                  # layer 4\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(10, activation = 'softmax')])                                # layer 5\n",
    "                    \n",
    "    if model_number == 3: \n",
    "        model = keras.models.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28, 28,1)),  # layer 1\n",
    "                    keras.layers.MaxPool2D((2,2)),                                                  # layer 2\n",
    "                    keras.layers.Conv2D(64, (3,3), activation = 'relu'),                            # layer 3\n",
    "                    keras.layers.Conv2D(64, (3,3), activation = 'relu'),                            # layer 4\n",
    "                    keras.layers.MaxPool2D((2,2)),                                                  # layer 5\n",
    "                    keras.layers.Conv2D(128, (3,3), activation = 'relu'),                           # layer 6\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(10, activation = 'softmax')])                                # layer 7\n",
    "    \n",
    "    return model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = select_model(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to see information of model, model.summary() will help\n",
    "### summary() is also built in function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                54090     \n",
      "=================================================================\n",
      "Total params: 54,410\n",
      "Trainable params: 54,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components in training step \n",
    "### Optimizer, Loss function, accuracy metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1422: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Step \n",
    "## Training for 5 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Dimension'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ec881beddcab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    918\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1590\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1592\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1445\u001b[0m                                        self._feed_sample_weight_modes)\n\u001b[0;32m   1446\u001b[0m     ]\n\u001b[1;32m-> 1447\u001b[1;33m     \u001b[0m_check_array_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1448\u001b[0m     _check_loss_and_target_compatibility(y, self._feed_loss_fns,\n\u001b[0;32m   1449\u001b[0m                                          self._feed_output_shapes)\n",
      "\u001b[1;32m~\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_check_array_lengths\u001b[1;34m(inputs, targets, weights)\u001b[0m\n\u001b[0;32m    230\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m   \u001b[0mset_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_of_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m   \u001b[0mset_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_of_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[0mset_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_of_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mset_of_lengths\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    228\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m   \u001b[0mset_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset_of_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'Dimension'"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels,  epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Step \n",
    "## Perform Test with Test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, accuracy = model.evaluate(test_images, test_labels, verbose = 2)\n",
    "print('\\nTest loss : ', test_loss)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before prediction, change test image's type to float 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.cast(test_images, tf.float32)\n",
    "pred = model.predict(test_images)\n",
    "Number = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Prediction : ', pred.shape)\n",
    "print('Test labels : ', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for plot images, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(Number[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                Number[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  plt.xticks(Number)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7b478b70af6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplot_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplot_value_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plot_image' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 1\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.subplot(1,2,1)\n",
    "plot_image(i, pred, test_labels, test_images)\n",
    "plt.subplot(1,2,2)\n",
    "plot_value_array(i, pred,  test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, pred, test_labels, test_images)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, pred, test_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images and probability that model predicted wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_mnist(prediction_array, true_label):\n",
    "    error_index = []\n",
    "    \n",
    "    for i in range(true_label.shape[0]):\n",
    "        if np.argmax(prediction_array[i]) != true_label[i]:\n",
    "            error_index.append(i)\n",
    "    return error_index\n",
    "\n",
    "# change num_cols, num_rows if you want to see more result.  \n",
    "def plot_error(index, prediction_array, true_label):\n",
    "    num_cols = 5\n",
    "    num_rows = 5\n",
    "    plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "\n",
    "    assert len(index) < num_cols * num_rows\n",
    "    for i in range(len(index)):\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "        idx = index[i]\n",
    "        plt.imshow(test_images[idx])\n",
    "        plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "        plt.bar(range(10), prediction_array[idx])\n",
    "        plt.xticks(Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find index of wrong prediction\n",
    "## Plot first 10 wrong predicted images and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = error_mnist(pred, test_labels)\n",
    "index_slice = index[:10]\n",
    "print(index[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error(index_slice, pred, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DONE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-87f6c984fac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mDONE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'DONE' is not defined"
     ]
    }
   ],
   "source": [
    "DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
